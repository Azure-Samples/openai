# Finetuning for Tone

## Methodology

### General Methodology

In this discussion, we will outline a general methodology for constructing a training dataset for fine-tuning, the fine-tuning process itself, and the evaluation of the fine-tuned model.

Our evaluation dataset is limited to a concise set of fewer than 200 "golden" test samples, for which both the questions and answers are predefined. Notably, the questions in this golden dataset lack any contextual information required for fine-tuning.

As a result, the primary challenges can be categorized into three key areas:

1. **Developing a comparable question set:** It is essential to generate a set of questions that share a similar "distribution" with the golden dataset while remaining distinct from it. This approach mitigates the risk of overfitting caused by training the model on answers that are already embedded in the dataset.

2. **Balancing overfitting and underfitting:** Striking the right balance is critical, as the goal is to fine-tune the model to capture the desired "tone" without compromising its generalization capabilities.

3. **Evaluating tone and response diversity:** Beyond measuring accuracy, it is important to establish effective methods for assessing the "tone" of the fine-tuned model. Additionally, strategies are required to intelligently manage the variability in responses generated by the chatbot.

### Constructing the Finetune dataset

Refer to the `Training_Data_Creation.ipynb` notebook for examples of implementation. The process for creating and refining training data involves the following steps:

1. **Select sample questions from the golden dataset:** Choose approximately 50 sample questions from the golden dataset, which is sufficient for `GPT4-o`.  
   *For instance: `By how much did the group's revenue increase from 2022 to 2023?`*

2. **Modify the question details:** Adjust specific details of the selected questions to avoid overfitting to the golden dataset. Examples of modifications include changing the year or the subsidiary referenced in the question.  
   *For example, the question may be rephrased as: `By how much did the group's revenue increase from 2021 to 2022?` Ensure that sufficient context exists in the backend repository to support answering the modified questions.*

3. **Generate answers using the chatbot:** Input the newly created questions into the chatbot to retrieve answers and extract the context needed for fine-tuning.

4. **Refine the answers:** Use a GPT-based rephrasing tool to refine the answers. This includes formatting the responses with tables where appropriate and modifying the tone to align with that of a financial expert.  
   For example:  
   ```python
   new_answer = "The group's revenue is ..."
   ```

### Finetuning

1. **Perform fine-tuning using OpenAI's fine-tuning framework:**  
   Initiate the fine-tuning process with OpenAI's default hyperparameter values as a starting point. Gradually refine the parameters by scaling epochs linearly (e.g., 1, 2, 3, ...) and adjusting the batch size exponentially (e.g., 1, 2, 4, ...). This method ensures a systematic exploration of the hyperparameter space.

   **Initialize**
   ![Initialize](.\Image\Initial_FT.png "Initialize Finetune in Azure AI")
   **Add training data**
   ![Training Data](.\Image\Training_Data.png "Add Training Data")
   **Add validation data**
   ![Validation Data](.\Image\Validation_Data.png "Add Validation Data")
   **Change hyperparameter**
   ![Hyperparameter Data](.\Image\hyperparameter.png "Change hyperparameter")

2. **Experiment with various batch sizes and epochs:**  
   Conduct fine-tuning experiments using different combinations of batch sizes and epochs. Compare the resulting performance metrics to identify the optimal settings for your model.

### Evaluation

Refer to the `Evaluating_the_output.ipynb` notebook for example implementations. The evaluation process for a newly fine-tuned model involves the following steps:

1. **Run the fine-tuned model multiple times:** Execute the model 10 times on the golden dataset questions, and collect the generated outputs.  
   *Note: `GPT4-o` exhibits variability in its responses even when the temperature is set to 0, making this step essential.*

2. **Evaluate accuracy:** Compare the accuracy of the generated responses for each question to assess the model's performance.

3. **Assess tone consistency:** Utilize a GPT-based prompt to evaluate the tone of the responses. Example prompts for tone evaluation are provided in `Evaluating_the_output.ipynb`.

## Lesson Learnt

1. **Utilize synthetic data for fine-tuning:** Creating synthetic data by modifying existing test data can be an effective strategy when the available test data are insufficient for fine-tuning purposes.

2. **Leverage small datasets effectively:** A relatively small fine-tuning dataset can yield satisfactory training results for models like `GPT4-o`, emphasizing the efficiency of fine-tuning on such models.

3. **Experiment with batch sizes and epochs to regulate training steps:** Adjusting batch sizes and epochs allows precise control over the total number of training steps. The total number of training steps often has a more significant impact on the model's performance than batch sizes or epochs individually.

4. **Identify the "Goldilocks zone" for training:** There exists an optimal balance where the desired tone can be effectively instilled in the model with only a minimal trade-off in accuracy. This balance is analogous to the variance-bias trade-off in machine learning. Identifying this point requires iterative experimentation and careful evaluation.
