{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759f9ec0",
   "metadata": {},
   "source": [
    "<h1 align =\"center\"> Shared Functions</h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Parameters\n",
    "\n",
    "\n",
    "Here we will load the configurations from _config.json_ file to setup deployment_name, openai_api_base, openai_api_key and openai_api_version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "with open(r'config.json') as config_file:\n",
    "    config_details = json.load(config_file)\n",
    "\n",
    "# Setting up the deployment name\n",
    "deployment_name = config_details['GPT-4V_MODEL']\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai_api_base = config_details['OPENAI_API_BASE']\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Currently OPENAI API have the following versions available: 2022-12-01. All versions follow the YYYY-MM-DD date structure.\n",
    "openai_api_version = config_details['OPENAI_API_VERSION']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciontion to Call GPT-4V API with Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GPT-4V API call with image\n",
    "def call_GPT4V_image(messages, ocr=False, grounding=False, in_context=None):\n",
    "    # Construct the API request URL\n",
    "    if ocr or grounding or in_context is not None:\n",
    "        api_url = f\"{openai_api_base}/openai/deployments/{deployment_name}/extensions/chat/completions?api-version={openai_api_version}\"\n",
    "    else:\n",
    "        api_url = f\"{openai_api_base}/openai/deployments/{deployment_name}/chat/completions?api-version={openai_api_version}\"\n",
    "\n",
    "    # Including the api-key in HTTP headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": openai_api_key,\n",
    "    }\n",
    "\n",
    "    # Payload for the request\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 800\n",
    "    }\n",
    "\n",
    "    if ocr or grounding:\n",
    "        payload[\"enhancements\"]={\n",
    "                            \"ocr\": {\n",
    "                                \"enabled\": ocr # Enable OCR enhancement\n",
    "                            },\n",
    "                            \"grounding\": {\n",
    "                                \"enabled\": grounding  # Enable grounding enhancement\n",
    "                            }\n",
    "                        }\n",
    "    if in_context is not None:\n",
    "        data_source = {\n",
    "            \"type\": \"AzureCognitiveSearch\",\n",
    "            \"parameters\": {\n",
    "                \"endpoint\": in_context.get(\"endpoint\"),\n",
    "                \"key\": in_context.get(\"key\"),\n",
    "                \"indexName\": in_context.get(\"indexName\"),\n",
    "            }\n",
    "        }\n",
    "        payload[\"dataSources\"] = [data_source]\n",
    "\n",
    "    # Send the request and handle the response\n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Raise an error for bad HTTP status codes\n",
    "        return response.json()\n",
    "    except requests.RequestException as e:\n",
    "        raise SystemExit(f\"Failed to make the request. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciontion to Call GPT-4V API with Video Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b3d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GPT-4V API call with video index\n",
    "def call_GPT4V_video(messages, vision_api, video_index):\n",
    "    # Construct the API request URL\n",
    "    api_url = f\"{openai_api_base}/openai/deployments/{deployment_name}/extensions/chat/completions?api-version={openai_api_version}\"\n",
    "\n",
    "    # Including the api-key in HTTP headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": openai_api_key,\n",
    "    }\n",
    "\n",
    "    # Payload for the request\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",       \n",
    "        \"dataSources\": [\n",
    "            {\n",
    "                \"type\": \"AzureComputerVisionVideoIndex\",\n",
    "                \"parameters\": {\n",
    "                    \"computerVisionBaseUrl\": f\"{vision_api.get('endpoint')}/computervision\",\n",
    "                    \"computerVisionApiKey\": vision_api.get('key'),\n",
    "                    \"indexName\": video_index.get('video_index_name'),\n",
    "                    \"videoUrls\": [video_index.get('video_SAS_url')]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"enhancements\": {\n",
    "                \"video\": {\n",
    "                    \"enabled\": True\n",
    "                }\n",
    "            },\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 800\n",
    "    }\n",
    "    \n",
    "     # Send the request and handle the response\n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Raise an error for bad HTTP status codes\n",
    "        return response.json()\n",
    "    except requests.RequestException as e:\n",
    "        raise SystemExit(f\"Failed to make the request. Error: {e}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Create Video Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_index(vision_api_endpoint, vision_api_key, index_name):\n",
    "    url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}?api-version=2023-05-01-preview\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key, \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"features\": [\n",
    "            {\"name\": \"vision\", \"domain\": \"surveillance\"},\n",
    "            {\"name\": \"speech\"}\n",
    "        ]\n",
    "    }\n",
    "    response = requests.put(url, headers=headers, data=json.dumps(data))\n",
    "    return response\n",
    "\n",
    "def add_video_to_index(vision_api_endpoint, vision_api_key, index_name, video_url, video_id):\n",
    "    url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}/ingestions/my-ingestion?api-version=2023-05-01-preview\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key, \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        'videos': [{'mode': 'add', 'documentId': video_id, 'documentUrl': video_url}]\n",
    "    }\n",
    "    response = requests.put(url, headers=headers, data=json.dumps(data))\n",
    "    return response\n",
    "\n",
    "def wait_for_ingestion_completion(vision_api_endpoint, vision_api_key, index_name, max_retries=30):\n",
    "    url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}/ingestions?api-version=2023-05-01-preview\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key}\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        time.sleep(10)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            state_data = response.json()\n",
    "            if state_data['value'][0]['state'] == 'Completed':\n",
    "                print(state_data)\n",
    "                print('Ingestion completed.')\n",
    "                return True\n",
    "        retries += 1\n",
    "    return False\n",
    "\n",
    "def process_video_indexing(vision_api_endpoint, vision_api_key, video_index_name, video_SAS_url, video_id):\n",
    "    # Step 1: Create an Index\n",
    "    response = create_video_index(vision_api_endpoint, vision_api_key, video_index_name)\n",
    "    print(response.status_code, response.text)\n",
    "\n",
    "    # Step 2: Add a video file to the index\n",
    "    response = add_video_to_index(vision_api_endpoint, vision_api_key, video_index_name, video_SAS_url, video_id)\n",
    "    print(response.status_code, response.text)\n",
    "\n",
    "    # Step 3: Wait for ingestion to complete\n",
    "    if not wait_for_ingestion_completion(vision_api_endpoint, vision_api_key, video_index_name):\n",
    "        print(\"Ingestion did not complete within the expected time.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
