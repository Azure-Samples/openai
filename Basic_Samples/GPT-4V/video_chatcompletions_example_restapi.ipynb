{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759f9ec0",
   "metadata": {},
   "source": [
    "<h1 align =\"center\"> REST API Video Samples</h1>\n",
    "<hr>\n",
    "   \n",
    "# Chat Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b3d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d4a0f",
   "metadata": {},
   "source": [
    "### Setup Parameters\n",
    "\n",
    "\n",
    "Here we will load the configurations from _config.json_ file to setup vision_api_key, vision_api_endpoint, deployment_name, openai_api_base, openai_api_key and openai_api_version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd85fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "with open(r'config.json') as config_file:\n",
    "    config_details = json.load(config_file)\n",
    "\n",
    "# Setting up the vision resource key\n",
    "vision_api_key = os.getenv(\"VISION_API_KEY\")\n",
    "\n",
    "# The base URL for your vision resource endpoint, e.g. \"https://<your-resource-name>.cognitiveservices.azure.com\"\n",
    "# You must create your resource in the East US region.\n",
    "vision_api_endpoint = config_details['VISION_API_ENDPOINT'] \n",
    "\n",
    "# Setting up the deployment name\n",
    "deployment_name = config_details['GPT-4V_MODEL']\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai_api_base = config_details['OPENAI_API_BASE']\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Currently OPENAI API have the following versions available: 2022-12-01. All versions follow the YYYY-MM-DD date structure.\n",
    "openai_api_version = config_details['OPENAI_API_VERSION']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Video Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "704ffbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 {\"name\":\"new-test-zhi-v2\",\"userData\":{},\"features\":[{\"name\":\"vision\",\"modelVersion\":\"2023-05-31\",\"domain\":\"surveillance\"},{\"name\":\"speech\",\"modelVersion\":\"2023-06-30\",\"domain\":\"generic\"}],\"eTag\":\"\\\"6e5e6f45329140d3905e165b96a419dd\\\"\",\"createdDateTime\":\"2023-11-20T22:36:02.9845660Z\",\"lastModifiedDateTime\":\"2023-11-20T22:36:02.9845660Z\"}\n",
      "202 {\"name\":\"my-ingestion\",\"state\":\"Running\",\"batchName\":\"d0fba86c-38a9-4492-9dfa-c48a120e6971\",\"createdDateTime\":\"2023-11-20T22:36:03.8751731Z\",\"lastModifiedDateTime\":\"2023-11-20T22:36:04.1096025Z\"}\n",
      "{'value': [{'name': 'my-ingestion', 'state': 'Completed', 'batchName': 'd0fba86c-38a9-4492-9dfa-c48a120e6971', 'createdDateTime': '2023-11-20T22:36:03.8751731Z', 'lastModifiedDateTime': '2023-11-20T22:36:27.7654671Z'}]}\n",
      "Ingestion completed.\n"
     ]
    }
   ],
   "source": [
    "video_SAS_url = config_details[\"VIDEO_SAS_URL\"] # Insert your video SAS URL, e.g. https://<your-storage-account-name>.blob.core.windows.net/<your-container-name>/<your-video-name>?<SAS-token>\n",
    "video_index_name = config_details[\"VIDEO_INDEX_NAME\"] # This index name must be unique\n",
    "video_id = config_details[\"VIDEO_INDEX_ID\"] # This video ID must be unique\n",
    "\n",
    "def create_video_index(vision_api_endpoint, vision_api_key, index_name):\n",
    "    url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}?api-version=2023-05-01-preview\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key, \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"features\": [\n",
    "            {\"name\": \"vision\", \"domain\": \"surveillance\"},\n",
    "            {\"name\": \"speech\"}\n",
    "        ]\n",
    "    }\n",
    "    response = requests.put(url, headers=headers, data=json.dumps(data))\n",
    "    return response\n",
    "\n",
    "def add_video_to_index(vision_api_endpoint, vision_api_key, index_name, video_url, video_id):\n",
    "    url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}/ingestions/my-ingestion?api-version=2023-05-01-preview\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key, \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        'videos': [{'mode': 'add', 'documentId': video_id, 'documentUrl': video_url}]\n",
    "    }\n",
    "    response = requests.put(url, headers=headers, data=json.dumps(data))\n",
    "    return response\n",
    "\n",
    "def wait_for_ingestion_completion(vision_api_endpoint, vision_api_key, index_name, max_retries=30):\n",
    "    url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}/ingestions?api-version=2023-05-01-preview\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key}\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        time.sleep(10)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            state_data = response.json()\n",
    "            if state_data['value'][0]['state'] == 'Completed':\n",
    "                print(state_data)\n",
    "                print('Ingestion completed.')\n",
    "                return True\n",
    "        retries += 1\n",
    "    return False\n",
    "\n",
    "\n",
    "# Step 1: Create an Index\n",
    "response = create_video_index(vision_api_endpoint, vision_api_key, video_index_name)\n",
    "print(response.status_code, response.text)\n",
    "\n",
    "# Step 2: Add a video file to the index\n",
    "response = add_video_to_index(vision_api_endpoint, vision_api_key, video_index_name, video_SAS_url, video_id)\n",
    "print(response.status_code, response.text)\n",
    "\n",
    "# Step 3: Wait for ingestion to complete\n",
    "if not wait_for_ingestion_completion(vision_api_endpoint, vision_api_key, video_index_name):\n",
    "    print(\"Ingestion did not complete within the expected time.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GPT-4V API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GPT-4V API call\n",
    "def call_GPT4V(vision_api_endpoint, vision_api_key, video_index_name, video_id, user_prompt, sys_message):\n",
    "    # Construct the API request URL\n",
    "    api_url = f\"{openai_api_base}/openai/deployments/{deployment_name}/extensions/chat/completions?api-version={openai_api_version}\"\n",
    "\n",
    "    # Including the api-key in HTTP headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": openai_api_key,\n",
    "    }\n",
    "\n",
    "    # Payload for the request\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",       \n",
    "        \"dataSources\": [\n",
    "            {\n",
    "                \"type\": \"AzureComputerVisionVideoIndex\",\n",
    "                \"parameters\": {\n",
    "                    \"computerVisionBaseUrl\": f\"{vision_api_endpoint}/computervision\",\n",
    "                    \"computerVisionApiKey\": vision_api_key,\n",
    "                    \"indexName\": video_index_name,\n",
    "                    \"videoUrls\": [video_SAS_url]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"enhancements\": {\n",
    "                \"video\": {\n",
    "                    \"enabled\": True\n",
    "                }\n",
    "            },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\", \n",
    "                        \"text\": sys_message\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"acv_document_id\",\n",
    "                            \"acv_document_id\": video_id\n",
    "                        }\n",
    "                    ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": user_prompt # Prompt for the user\n",
    "                        }\n",
    "                    ]\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 800\n",
    "    }\n",
    "\n",
    "    # Send the request and handle the response\n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Raise an error for bad HTTP status codes\n",
    "        return response.json()\n",
    "    except requests.RequestException as e:\n",
    "        raise SystemExit(f\"Failed to make the request. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call GPT-4V On The Entire Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6165c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video advertisement showcases a software product that appears to integrate seamlessly into various aspects of personal and professional life.\n",
      "It starts by setting a tranquil and modern scene, then transitions into a user interface where a voice command prompts \"Hello Copilot\" and \"Create a picture,\" suggesting voice-activated functionality and creative capabilities.\n",
      "\n",
      "The video moves on to display features that allow users to explore variations within the software, likely for customization or design purposes.\n",
      "It further demonstrates productivity elements, such as typing a document with the title \"Sustainable Design: What, Why, and How,\" hinting at the software's utility in creating written content.\n",
      "\n",
      "Throughout the ad, there is an emphasis on organization and planning, with the interface responding to commands like \"Organize my plans.\" The product also seems to offer relaxation or lifestyle features, as indicated by the command \"Help me relax,\" which transitions to a scene with a person in a serene environment, suggesting work-life balance.\n",
      "\n",
      "The lighting in the video is soft and the color palette is composed of calming blues and purples, reinforcing the idea of a stress-free interaction with technology.\n",
      "There are no humans directly shown interacting with the product, but the presence of a user is implied through the voice commands and the final scene of a comfortable workspace.\n",
      "\n",
      "In summary, the main message of the video is to convey the versatility, user-friendliness, and adaptive nature of the software, designed to enhance creativity, productivity, and personal well-being, all within a streamlined and calming user experience.\n",
      "The advertisement ends with the Microsoft logo, indicating the company behind the product.\n"
     ]
    }
   ],
   "source": [
    "# System messages and user prompt\n",
    "sys_message = \"\"\"\n",
    "Your task is to assist in analyzing and optimizing creative assets. \n",
    "You will be presented with advertisement videos for products. \n",
    "First describe the video in detail paying close attention to Product characteristics highlighted, \n",
    "Background images, Lighting, Color Palette and Human characteristics for persons in the video. \n",
    "Finally provide a summary of the video and talk about the main message the advertisement video tries to convey to the viewer. \n",
    "\"\"\"\n",
    "user_prompt = \"Summarize the ad video\"\n",
    "\n",
    "# Call GPT-4V API and print the response\n",
    "try:\n",
    "    response = call_GPT4V(vision_api_endpoint, vision_api_key, video_index_name, video_id, user_prompt, sys_message)\n",
    "    text = response['choices'][0]['message']['content']\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "    for sentence in sentences:  # Print the content of the response\n",
    "        print(sentence)\n",
    "except requests.RequestException as e:\n",
    "    raise SystemExit(f\"Failed to make the request. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call GPT-4V On Each Video Chunk Sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Length: 46.13 seconds\n",
      "Segment 1: How many scenes from 0s to 20s?\n",
      "Segment 2: How many scenes from 20s to 40s?\n",
      "Segment 3: How many scenes from 40s to 46.13s?\n",
      "From 40s to 46.13s, there are two scenes:\n",
      "\n",
      "1.\n",
      "Scene 10: A close-up of a search bar with the text \"Turn on dark mode\" and a dark background with floral elements (00:39 - 00:42)\n",
      "2.\n",
      "Scene 11: A final screen with the text \"Copilot\" and the tagline \"Your everyday AI companion\" (00:42 - 00:46.13)\n",
      "\n",
      "Combining the scenes from the previous segments with the scenes from 40s to 46.13s, we have eleven scenes in total:\n",
      "\n",
      "1.\n",
      "A room with a computer on a desk and a view outside to a garden and floating islands (00:00 - 00:02.900000)\n",
      "2.\n",
      "A close-up of a search bar with the text \"Hello Copilot\" (00:02.900000 - 00:05.766667)\n",
      "3.\n",
      "A transition effect with a blue gradient (00:05.766667 - 00:08.633333)\n",
      "4.\n",
      "A desktop screen showing a photo editing interface (00:08.633333 - 00:11.500000)\n",
      "5.\n",
      "A desktop screen with a browser open showing a web page with the title \"Sustainable Design: What, Why, and How\" (00:18.500000 - 00:21.366667)\n",
      "6.\n",
      "A transition effect with a blurred screen (00:21.366667 - 00:24.233333)\n",
      "7.\n",
      "A desktop screen displaying a folder window and a colorful note widget (00:24.233333 - 00:27.100000)\n",
      "8.\n",
      "A close-up of a search bar with the text \"Organize my\" (00:27.100000 - 00:30.033333)\n",
      "9.\n",
      "A close-up of a search bar with the text \"He\" and a background that suggests a night mode setting (00:30.033333 - 00:33.033333)\n",
      "10.\n",
      "A close-up of a search bar with the text \"Turn on dark mode\" and a dark background with floral elements (00:39 - 00:42)\n",
      "11.\n",
      "A final screen with the text \"Copilot\" and the tagline \"Your everyday AI companion\" (00:42 - 00:46.13)\n"
     ]
    }
   ],
   "source": [
    "def download_video(sas_url, local_file_path):\n",
    "    try:\n",
    "        response = requests.get(sas_url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(local_file_path, 'wb') as file:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    file.write(chunk)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Download failed with status code: {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during download: {e}\")\n",
    "        return False\n",
    "\n",
    "def get_video_length(file_path):\n",
    "    try:\n",
    "        with VideoFileClip(file_path) as video:\n",
    "            return video.duration\n",
    "    except Exception as e:\n",
    "        print(f\"Error in getting video length: {e}\")\n",
    "        return None\n",
    "\n",
    "# Define the number of seconds for each segment\n",
    "chunk_size = 20\n",
    "# Download the video\n",
    "local_file_path = \"downloaded_video.mp4\"\n",
    "if download_video(video_SAS_url, local_file_path):\n",
    "    video_length = get_video_length(local_file_path)\n",
    "    os.remove(local_file_path)\n",
    "\n",
    "    if video_length is not None:\n",
    "        print(f\"Video Length: {video_length} seconds\")\n",
    "        sys_message = f\"\"\"\n",
    "        The total length of the video is {video_length}s. Your task is to assist in finding all scenes in this video.\n",
    "        You also need to describe each scene with start and end time. \n",
    "        \"\"\"\n",
    "        number_of_segments = int(video_length // chunk_size)\n",
    "        updated_response = \"\"\n",
    "        for i in range(number_of_segments + 1): # Include the last segment\n",
    "            start_time = i * chunk_size\n",
    "            end_time = min((i + 1) * chunk_size, video_length)\n",
    "            user_prompt = f\"How many scenes from {start_time}s to {end_time}s?\"\n",
    "            print(f\"Segment {i+1}: {user_prompt}\")\n",
    "            if i > 0:\n",
    "                user_prompt += f\"\"\"And here are scenes in the previous segments: {updated_response}. \n",
    "                                You need to combine the scenes in the previous segments with the scenes in this segment and provide a summary.\n",
    "                                \"\"\"\n",
    "            \n",
    "            response = call_GPT4V(vision_api_endpoint, vision_api_key, video_index_name, video_id, user_prompt, sys_message)\n",
    "            updated_response = response['choices'][0]['message']['content']\n",
    "            #print(f\"Response for segment {i+1}: {updated_response}\")\n",
    "            time.sleep(2) # Avoid throttling\n",
    "        \n",
    "        # Print the final response\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', updated_response)\n",
    "        for sentence in sentences:  # Print the content of the response\n",
    "            print(sentence)\n",
    "    else:\n",
    "        print(\"Failed to process video length.\")\n",
    "else:\n",
    "    print(\"Failed to download video.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
