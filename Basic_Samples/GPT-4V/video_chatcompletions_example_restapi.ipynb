{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759f9ec0",
   "metadata": {},
   "source": [
    "<h1 align =\"center\"> REST API Video Samples</h1>\n",
    "<hr>\n",
    "   \n",
    "# Chat Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d4a0f",
   "metadata": {},
   "source": [
    "### Setup Parameters\n",
    "\n",
    "\n",
    "Here we will load the configurations from _config.json_ file to setup vision_api_key, vision_api_endpoint, deployment_name, openai_api_base, openai_api_key and openai_api_version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "with open(r'config.json') as config_file:\n",
    "    config_details = json.load(config_file)\n",
    "\n",
    "# Setting up the vision resource key\n",
    "vision_api_key = os.getenv(\"VISION_API_KEY\")\n",
    "\n",
    "# The base URL for your vision resource endpoint, e.g. \"https://<your-resource-name>.cognitiveservices.azure.com\"\n",
    "# You must create your resource in the East US region.\n",
    "vision_api_endpoint = config_details['VISION_API_ENDPOINT'] \n",
    "\n",
    "# Setting up the deployment name\n",
    "deployment_name = config_details['GPT-4V_MODEL']\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai_api_base = config_details['OPENAI_API_BASE']\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Currently OPENAI API have the following versions available: 2022-12-01. All versions follow the YYYY-MM-DD date structure.\n",
    "openai_api_version = config_details['OPENAI_API_VERSION']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Video Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ffbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_SAS_url = \"your_SAS_url_here\" # Insert your video SAS URL, e.g. https://<your-storage-account-name>.blob.core.windows.net/<your-container-name>/<your-video-name>?<SAS-token>\n",
    "video_index_name = \"unique_video_index_name\" # This index name must be unique\n",
    "video_id = \"unique_video_id\" # This video ID must be unique\n",
    "\n",
    "def create_video_index(vision_api_endpoint, vision_api_key, index_name):\n",
    "    url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}?api-version=2023-05-01-preview\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key, \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"features\": [\n",
    "            {\"name\": \"vision\", \"domain\": \"surveillance\"},\n",
    "            {\"name\": \"speech\"}\n",
    "        ]\n",
    "    }\n",
    "    response = requests.put(url, headers=headers, data=json.dumps(data))\n",
    "    return response\n",
    "\n",
    "def add_video_to_index(vision_api_endpoint, vision_api_key, index_name, video_url, video_id):\n",
    "    url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}/ingestions/my-ingestion?api-version=2023-05-01-preview\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key, \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        'videos': [{'mode': 'add', 'documentId': video_id, 'documentUrl': video_url}]\n",
    "    }\n",
    "    response = requests.put(url, headers=headers, data=json.dumps(data))\n",
    "    return response\n",
    "\n",
    "def wait_for_ingestion_completion(vision_api_endpoint, vision_api_key, index_name, max_retries=30):\n",
    "    url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}/ingestions?api-version=2023-05-01-preview\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key}\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        time.sleep(10)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            state_data = response.json()\n",
    "            if state_data['value'][0]['state'] == 'Completed':\n",
    "                print(state_data)\n",
    "                print('Ingestion completed.')\n",
    "                return True\n",
    "        retries += 1\n",
    "    return False\n",
    "\n",
    "\n",
    "# Step 1: Create an Index\n",
    "response = create_video_index(vision_api_endpoint, vision_api_key, video_index_name)\n",
    "print(response.status_code, response.text)\n",
    "\n",
    "# Step 2: Add a video file to the index\n",
    "response = add_video_to_index(vision_api_endpoint, vision_api_key, video_index_name, video_SAS_url, video_id)\n",
    "print(response.status_code, response.text)\n",
    "\n",
    "# Step 3: Wait for ingestion to complete\n",
    "if not wait_for_ingestion_completion(vision_api_endpoint, vision_api_key, video_index_name):\n",
    "    print(\"Ingestion did not complete within the expected time.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call GPT-4V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6165c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System messages and user prompt\n",
    "sys_message = \"\"\"\n",
    "Your task is to assist in analyzing and optimizing creative assets. \n",
    "You will be presented with advertisement videos for products. \n",
    "First describe the video in detail paying close attention to Product characteristics highlighted, \n",
    "Background images, Lighting, Color Palette and Human characteristics for persons in the video. \n",
    "Finally provide a summary of the video and talk about the main message the advertisement video tries to convey to the viewer. \n",
    "\"\"\"\n",
    "user_prompt = \"Summarize the ad video\"\n",
    "\n",
    "# Construct the API request URL\n",
    "api_url = f\"{openai_api_base}/openai/deployments/{deployment_name}/extensions/chat/completions?api-version={openai_api_version}\"\n",
    "\n",
    "# Including the api-key in HTTP headers\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": openai_api_key,\n",
    "}\n",
    "\n",
    "# Payload for the request\n",
    "payload = {\n",
    "  \"dataSources\": [\n",
    "    {\n",
    "      \"type\": \"AzureComputerVisionVideoIndex\",\n",
    "      \"parameters\": {\n",
    "        \"computerVisionResource\": f\"{vision_api_endpoint}/computervision\",\n",
    "        \"computerVisionApiKey\": vision_api_key,\n",
    "        \"indexName\": video_index_name,\n",
    "        \"videoUrls\": [video_SAS_url]\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"enhancements\": {\n",
    "        \"video\": {\n",
    "            \"enabled\": True\n",
    "        }\n",
    "    },\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        sys_message\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"acv-document-id\": video_id\n",
    "        },\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        user_prompt\n",
    "      ]\n",
    "    }, \n",
    "  ],\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"max_tokens\": 800\n",
    "}\n",
    "\n",
    "# Send the request and handle the response\n",
    "try:\n",
    "    response = requests.post(api_url, headers=headers, json=payload)\n",
    "    response.raise_for_status()  # Raise an error for bad HTTP status codes\n",
    "    response_content = response.json()\n",
    "    print(response_content['choices'][0]['message']['content'])  # Print the content of the response\n",
    "except requests.RequestException as e:\n",
    "    raise SystemExit(f\"Failed to make the request. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
