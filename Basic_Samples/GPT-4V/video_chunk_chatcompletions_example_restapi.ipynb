{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759f9ec0",
   "metadata": {},
   "source": [
    "<h1 align =\"center\"> REST API Video Chunk Samples</h1>\n",
    "<hr>\n",
    "   \n",
    "# Chat Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b3d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "from moviepy.editor import VideoFileClip\n",
    "%run shared_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d4a0f",
   "metadata": {},
   "source": [
    "### Setup Parameters\n",
    "\n",
    "\n",
    "Here we will load the configurations from _config.json_ file to setup vision_api_key, vision_api_endpoint, video_SAS_url, video_index_name, and video_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd85fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "with open(r'config.json') as config_file:\n",
    "    config_details = json.load(config_file)\n",
    "\n",
    "# Setting up the vision resource key\n",
    "vision_api_key = os.getenv(\"VISION_API_KEY\")\n",
    "\n",
    "# The base URL for your vision resource endpoint, e.g. \"https://<your-resource-name>.cognitiveservices.azure.com\"\n",
    "# You must create your resource in the East US region.\n",
    "vision_api_endpoint = config_details['VISION_API_ENDPOINT']\n",
    "\n",
    "# Insert your video SAS URL, e.g. https://<your-storage-account-name>.blob.core.windows.net/<your-container-name>/<your-video-name>?<SAS-token>\n",
    "video_SAS_url = \"https://gpt4vsamples.blob.core.windows.net/videos/Redwire%20Field%20Trip%20-%203D%20Printing%20a%20Zune.mkv\" #config_details[\"VIDEO_SAS_URL\"]\n",
    "\n",
    "# This index name must be unique\n",
    "video_index_name = config_details[\"VIDEO_INDEX_NAME\"]\n",
    "\n",
    "# This video ID must be unique\n",
    "video_id = config_details[\"VIDEO_INDEX_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Video Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "704ffbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You only need to run this cell once to create the index\n",
    "process_video_indexing(vision_api_endpoint, vision_api_key, video_index_name, video_SAS_url, video_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call GPT-4V API with Video Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Length: 437.28 seconds\n",
      "Segment 1: How many scenes from 0s to 20s?\n",
      "Segment 2: How many scenes from 20s to 40s?\n",
      "Segment 3: How many scenes from 40s to 60s?\n",
      "Segment 4: How many scenes from 60s to 80s?\n",
      "Segment 5: How many scenes from 80s to 100s?\n",
      "Segment 6: How many scenes from 100s to 120s?\n",
      "Segment 7: How many scenes from 120s to 140s?\n",
      "Segment 8: How many scenes from 140s to 160s?\n",
      "Segment 9: How many scenes from 160s to 180s?\n",
      "Segment 10: How many scenes from 180s to 200s?\n",
      "Segment 11: How many scenes from 200s to 220s?\n",
      "Segment 12: How many scenes from 220s to 240s?\n",
      "Segment 13: How many scenes from 240s to 260s?\n",
      "Segment 14: How many scenes from 260s to 280s?\n",
      "Segment 15: How many scenes from 280s to 300s?\n",
      "Segment 16: How many scenes from 300s to 320s?\n",
      "Segment 17: How many scenes from 320s to 340s?\n",
      "Segment 18: How many scenes from 340s to 360s?\n",
      "Segment 19: How many scenes from 360s to 380s?\n",
      "Segment 20: How many scenes from 380s to 400s?\n",
      "Segment 21: How many scenes from 400s to 420s?\n",
      "Segment 22: How many scenes from 420s to 437.28s?\n",
      "From 420s to 437.28s, there is one continuous scene.\n",
      "This scene is a continuation from the previous segment, showing more of the facility's advanced technology.\n",
      "\n",
      "Combining this with the previous segments, the total number of scenes from 0s to 437.28s is twenty-three:\n",
      "\n",
      "1.\n",
      "From 0s to 20s, one continuous scene.\n",
      "2.\n",
      "From 20s to 40s, a scene featuring a red and silver object with a circular control interface.\n",
      "3.\n",
      "From 40s to 60s, a scene with an intense orange and white color scheme.\n",
      "4.\n",
      "From 60s to 80s, a close-up of a green and orange electronic device.\n",
      "5.\n",
      "From 80s to 100s, a scene featuring a 3D printer.\n",
      "6.\n",
      "From 100s to 120s, a space-themed animation with a cartoon dog.\n",
      "7.\n",
      "From 120s to 140s, continuation of the close-up of the red electronic device.\n",
      "8.\n",
      "From 140s to 160s, a bright star-like object transitioning to a Mars-like landscape.\n",
      "9.\n",
      "From 160s to 180s, a scene in a laboratory environment.\n",
      "10.\n",
      "From 180s to 200s, continuation within the laboratory environment.\n",
      "11.\n",
      "From 200s to 220s, the same high-tech laboratory environment.\n",
      "12.\n",
      "From 220s to 240s, a scene with a robotic arm.\n",
      "13.\n",
      "From 240s to 260s, an indoor setting with a modern doorway.\n",
      "14.\n",
      "From 260s to 280s, continuation of the indoor setting with the transportation pod.\n",
      "15.\n",
      "From 280s to 300s, one continuous scene extending from the previous segment.\n",
      "16.\n",
      "From 300s to 320s, a scene inside a control room with various monitors and equipment.\n",
      "17.\n",
      "From 320s to 340s, continuation of the scene with the \"MADE IN SPACE\" equipment inside the facility.\n",
      "18.\n",
      "From 340s to 360s, continuation of the scene inside the facility focusing on the \"MADE IN SPACE\" equipment.\n",
      "19.\n",
      "From 360s to 380s, continuation of the scene showing a close-up of the \"MADE IN SPACE\" equipment and its components.\n",
      "20.\n",
      "From 380s to 400s, continuation of the scene featuring the \"MADE IN SPACE\" equipment within the facility.\n",
      "21.\n",
      "From 400s to 420s, continuation of the scene, further showcasing the interior of the facility and its technology.\n",
      "22.\n",
      "From 420s to 437.28s, continuation of the scene, highlighting advanced technology at the facility.\n",
      "\n",
      "These twenty-three scenes together provide a comprehensive visual exploration of the different settings and technological advancements highlighted in the video.\n"
     ]
    }
   ],
   "source": [
    "#  Call GPT-4V API with Video Index on Each Video Chunk Sequentially\n",
    "\n",
    "def download_video(sas_url, local_file_path):\n",
    "    try:\n",
    "        response = requests.get(sas_url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(local_file_path, 'wb') as file:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    file.write(chunk)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Download failed with status code: {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during download: {e}\")\n",
    "        return False\n",
    "\n",
    "def get_video_length(file_path):\n",
    "    try:\n",
    "        with VideoFileClip(file_path) as video:\n",
    "            return video.duration\n",
    "    except Exception as e:\n",
    "        print(f\"Error in getting video length: {e}\")\n",
    "        return None\n",
    "\n",
    "# Define the config values\n",
    "vision_api_config = {\n",
    "    \"endpoint\": vision_api_endpoint,\n",
    "    \"key\": vision_api_key\n",
    "}\n",
    "\n",
    "video_config = {\n",
    "    \"video_SAS_url\": video_SAS_url,\n",
    "    \"video_index_name\": video_index_name,\n",
    "}\n",
    "\n",
    "# Define the number of seconds for each segment\n",
    "chunk_size = 20 # seconds\n",
    "# Download the video\n",
    "local_file_path = \"downloaded_video.mp4\"\n",
    "if download_video(video_SAS_url, local_file_path):\n",
    "    video_length = get_video_length(local_file_path)\n",
    "    os.remove(local_file_path)\n",
    "\n",
    "    if video_length is not None:\n",
    "        print(f\"Video Length: {video_length} seconds\")\n",
    "        sys_message = f\"\"\"\n",
    "        The total length of the video is {video_length}s. Your task is to assist in finding all scenes in this video.\n",
    "        You also need to describe each scene with start and end time. \n",
    "        \"\"\"\n",
    "        number_of_segments = int(video_length // chunk_size)\n",
    "        updated_response = \"\"\n",
    "        for i in range(number_of_segments + 1): # Include the last segment\n",
    "            start_time = i * chunk_size\n",
    "            end_time = min((i + 1) * chunk_size, video_length)\n",
    "            user_prompt = f\"How many scenes from {start_time}s to {end_time}s?\"\n",
    "            print(f\"Segment {i+1}: {user_prompt}\")\n",
    "            if i > 0:\n",
    "                user_prompt += f\"\"\"And here are scenes in the previous segments: {updated_response}. \n",
    "                                You need to combine the scenes in the previous segments with the scenes in this segment and provide a summary.\n",
    "                                \"\"\"\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "                {\"role\": \"user\", \"content\": [{\"type\": \"acv_document_id\", \"acv_document_id\": video_id}]},\n",
    "                {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": user_prompt}]}\n",
    "            ]\n",
    "\n",
    "            response = call_GPT4V_video(messages, vision_api=vision_api_config, video_index=video_config)\n",
    "            updated_response = response['choices'][0]['message']['content']\n",
    "            #print(f\"Response for segment {i+1}: {updated_response}\")\n",
    "            time.sleep(2) # Avoid throttling\n",
    "        \n",
    "        # Print the final response\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', updated_response)\n",
    "        for sentence in sentences:  # Print the content of the response\n",
    "            print(sentence)\n",
    "    else:\n",
    "        print(\"Failed to process video length.\")\n",
    "else:\n",
    "    print(\"Failed to download video.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
