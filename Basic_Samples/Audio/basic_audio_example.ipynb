{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio transcription and translation (preview) example\n",
    "\n",
    "The example shows how to use the Azure OpenAI Whisper model to transcribe and translate audio files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "\n",
    "First, we install the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"openai>=0.28.1\"\n",
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Next, we'll import our libraries and configure the Python OpenAI SDK to work with the Azure OpenAI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_base = os.environ[\"OPENAI_API_BASE\"]\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-09-01-preview\"\n",
    "\n",
    "deployment_id = os.environ[\"WHISPER_DEPLOYMENT_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio transcription\n",
    "\n",
    "Audio transcription, or speech-to-text, is the process of converting spoken words into text. Use the `openai.Audio.transcribe` method to transcribe an audio file stream to text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ocelot, Lepardus paradalis, is a small wild cat native to the southwestern United States, Mexico, and Central and South America. This medium-sized cat is characterized by solid black spots and streaks on its coat, round ears, and white neck and undersides. It weighs between 8 and 15.5 kilograms, 18 and 34 pounds, and reaches 40 to 50 centimeters – 16 to 20 inches – at the shoulders. It was first described by Carl Linnaeus in 1758. Two subspecies are recognized, L. p. paradalis and L. p. mitis. Typically active during twilight and at night, the ocelot tends to be solitary and territorial. It is efficient at climbing, leaping, and swimming. It preys on small terrestrial mammals such as armadillo, opossum, and lagomorphs.\n"
     ]
    }
   ],
   "source": [
    "transcription = openai.Audio.transcribe(\n",
    "    file=open(\"recordings/audio_en.wav\", \"rb\"),\n",
    "    model=\"whisper-1\",\n",
    "    deployment_id=deployment_id,\n",
    ")\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio translation\n",
    "\n",
    "Audio translation can be used to translate the given audio file into English (Note: only English supported currently). In this example, we provide an audio file about Custom Speech recorded in Spanish. The result contains the English translation of the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content, such as data, models, tests and connection points, is organized into projects in the Custom Speech Portal. Each project is specific to a domain and a country or language. For example, you can create a project for call centers that use English in the United States. To create your first project, select speech-to-text-custom-speech. Then, click on New Project. Follow the assistant's instructions to create the project. After creating the project, you will see four tabs, data, tests, training and implementation. Use the links included in the following steps to learn how to use each tab.\n"
     ]
    }
   ],
   "source": [
    "translation = openai.Audio.translate(\n",
    "    file=open(\"recordings/audio_es.wav\", \"rb\"),\n",
    "    model=\"whisper-1\",\n",
    "    deployment_id=deployment_id\n",
    ")\n",
    "print(translation.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
