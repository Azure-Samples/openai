{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Whisper transcriptions: pre- & post-processing techniques\n",
    "\n",
    "This notebook offers a guide to improve the Whisper's transcriptions. We'll streamline your audio data via trimming and segmentation, enhancing Whisper's transcription quality. After transcriptions, we'll refine the output by adding punctuation, adjusting product terminology (e.g., 'five two nine' to '529'), and mitigating Unicode issues. These strategies will help improve the clarity of your transcriptions, but remember, customization based on your unique use-case may be beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "Install the Azure Open AI SDK using the below command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.AI.OpenAI, 1.0.0-beta.9</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Azure.AI.OpenAI, 1.0.0-beta.9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.DotNet.Interactive.AIUtilities, 1.0.0-beta.23552.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget:Microsoft.DotNet.Interactive.AIUtilities, 1.0.0-beta.23552.1\"\n",
    "\n",
    "using Microsoft.DotNet.Interactive;\n",
    "using Microsoft.DotNet.Interactive.AIUtilities;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell, it will prompt you for the apiKey, endPoint, gtpDeployment, and whisperDeployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var azureOpenAIKey = await Kernel.GetPasswordAsync(\"Provide your OPEN_AI_KEY\");\n",
    "\n",
    "// Your endpoint should look like the following https://YOUR_OPEN_AI_RESOURCE_NAME.openai.azure.com/\n",
    "var azureOpenAIEndpoint = await Kernel.GetInputAsync(\"Provide the OPEN_AI_ENDPOINT\");\n",
    "\n",
    "// Enter the deployment name you chose when you deployed the model.\n",
    "var gptDeployment = await Kernel.GetInputAsync(\"Provide gpt deployment name\");\n",
    "\n",
    "var whisperDeployment = await Kernel.GetInputAsync(\"Provide whisper deployment name\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import namesapaces and create an instance of `OpenAiClient` using the `azureOpenAIEndpoint` and the `azureOpenAIKey`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Azure;\n",
    "using Azure.AI.OpenAI;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "OpenAIClient client = new (new Uri(azureOpenAIEndpoint), new AzureKeyCredential(azureOpenAIKey.GetClearTextPassword()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "To get started let's import a few different libraries:\n",
    "\n",
    " - [Naudio](https://github.com/naudio/NAudio) is a simple and easy-to-use library for audio processing tasks such as slicing, concatenating, and exporting audio files.\n",
    "\n",
    " - For our audio file, we'll use a fictional earnings call written by ChatGPT and read aloud by the author.This audio file is relatively short, but hopefully provides you with an illustrative idea of how these pre and post processing steps can be applied to any audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using System.Net.Http;\n",
    "using System.IO;\n",
    "\n",
    "// set download paths\n",
    "var earningsCallUrl = \"https://cdn.openai.com/API/examples/data/EarningsCall.wav\";\n",
    "\n",
    "//set local save locations\n",
    "var earningsCallFilepath = \"./EarningsCall.wav\";\n",
    "\n",
    "// download the file\n",
    "var httpClient = new HttpClient();\n",
    "using (var stream = await httpClient.GetStreamAsync(earningsCallUrl))\n",
    "{\n",
    "    if(File.Exists(earningsCallFilepath))\n",
    "    {\n",
    "        File.Delete(earningsCallFilepath);\n",
    "    }\n",
    "    using (var fileStream = new FileStream(earningsCallFilepath, FileMode.CreateNew))\n",
    "    {\n",
    "      \n",
    "        await stream.CopyToAsync(fileStream);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>NAudio, 2.2.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: NAudio, 2.2.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At times, files with long silences at the beginning can cause Whisper to transcribe the audio incorrectly. We'll use `NAudio`` to detect and trim the silence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using NAudio.Wave;\n",
    "using System.IO;\n",
    "\n",
    "public record Silence(long Start, long End, TimeSpan Duration);\n",
    "\n",
    "// Find silcence in the file so we can trim it and split by silences\n",
    "public Silence[] FindSilences(string fileName, double silenceThreshold = -40){\n",
    "\n",
    "    bool IsSilence(float amplitude, double threshold)\n",
    "    {\n",
    "        double dB = 20 * Math.Log10(Math.Abs(amplitude));\n",
    "        return dB < threshold;\n",
    "    }\n",
    "\n",
    "    var silences = new List<Silence>();\n",
    "    using (var reader = new AudioFileReader(fileName))\n",
    "    {\n",
    "        var buffer = new float[reader.WaveFormat.SampleRate * 4];\n",
    "    \n",
    "        long start = 0;\n",
    "        bool eof = false;\n",
    "        long counter = 0;\n",
    "        bool detected = false;\n",
    "        while (!eof)\n",
    "        {\n",
    "            int samplesRead = reader.Read(buffer, 0, buffer.Length);\n",
    "            if (samplesRead == 0)\n",
    "                {\n",
    "                    eof = true;\n",
    "                    if (detected){\n",
    "                        double silenceSamples = (double)counter / reader.WaveFormat.Channels;\n",
    "                        double silenceDuration = (silenceSamples / reader.WaveFormat.SampleRate) * 1000;\n",
    "                        silences.Add(new Silence(start, start + counter, TimeSpan.FromMilliseconds(silenceDuration)));\n",
    "                    }\n",
    "                }\n",
    "\n",
    "            for (int n = 0; n < samplesRead; n++)\n",
    "            {\n",
    "                if (IsSilence(buffer[n], silenceThreshold))\n",
    "                {\n",
    "                    detected = true;\n",
    "                    counter++;\n",
    "                }\n",
    "                else{\n",
    "                    if(detected)\n",
    "                    {\n",
    "                        double silenceSamples = (double)counter / reader.WaveFormat.Channels;\n",
    "                        double silenceDuration = (silenceSamples / reader.WaveFormat.SampleRate) * 1000;\n",
    "                        var last =silences.Count - 1;\n",
    "                        if (last >= 0)\n",
    "                        {\n",
    "                            // see if we can merge with the last silence\n",
    "                            var gap = start - silences[last].End;\n",
    "                            var gapDuration = (double)gap / reader.WaveFormat.SampleRate * 1000;\n",
    "                            if (gapDuration < 500)\n",
    "                            {\n",
    "                                silenceDuration = silenceDuration + silences[last].Duration.TotalMilliseconds;\n",
    "                                silences[last] = new Silence(silences[last].Start, counter + silences[last].End, TimeSpan.FromMilliseconds(silenceDuration));\n",
    "                            }\n",
    "                            else\n",
    "                            {\n",
    "                                silences.Add(new Silence(start, counter, TimeSpan.FromMilliseconds(silenceDuration)));\n",
    "                            }\n",
    "                        }\n",
    "                        else\n",
    "                        {\n",
    "                            silences.Add(new Silence(start, counter, TimeSpan.FromMilliseconds(silenceDuration)));\n",
    "                        }\n",
    "\n",
    "                        start = start + counter;\n",
    "                        counter = 0;\n",
    "                        detected = false;\n",
    "                    }\n",
    "                }            \n",
    "            }        \n",
    "        }\n",
    "    }\n",
    "    return silences.ToArray();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "public record AudioSegment(long Start, long End, TimeSpan Duration);\n",
    "\n",
    "public AudioSegment[] FindAudibleSegments(string fileName, Silence[] silences){\n",
    "    var segments = new List<AudioSegment>();\n",
    "    using (var reader = new AudioFileReader(fileName)){\n",
    "        var totalSamples = reader.Length;\n",
    "        for(var i = 0; i< silences.Length; i++){\n",
    "            if(i == 0 && silences[i].Start > 0){\n",
    "                segments.Add(new AudioSegment(0, silences[i].Start, TimeSpan.FromMilliseconds(silences[i].Start / reader.WaveFormat.SampleRate * 1000)));\n",
    "            }\n",
    "            if(i == silences.Length - 1 && silences[i].End < totalSamples){\n",
    "                segments.Add(new AudioSegment(silences[i].End, totalSamples, TimeSpan.FromMilliseconds((totalSamples - silences[i].End) / reader.WaveFormat.SampleRate * 1000)));\n",
    "            }\n",
    "            if(i < silences.Length - 1){\n",
    "                var current = silences[i];\n",
    "                var next = silences[i+1];\n",
    "                if(current.End < next.Start)\n",
    "                {\n",
    "                    segments.Add(new AudioSegment(current.End, next.Start, TimeSpan.FromMilliseconds((next.Start - current.End) / reader.WaveFormat.SampleRate * 1000)));\n",
    "                    segments.Last().Display();\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        }\n",
    "    }\n",
    "    return segments.ToArray();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've set the decibel threshold of -19. You can change this if you would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>value</th></tr></thead><tbody><tr><td>0</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Silence { Start = 0, End = 5211100, Duration = 00:03:37.1268367 }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Start</td><td><div class=\"dni-plaintext\"><pre>0</pre></div></td></tr><tr><td>End</td><td><div class=\"dni-plaintext\"><pre>5211100</pre></div></td></tr><tr><td>Duration</td><td><span>00:03:37.1268367</span></td></tr></tbody></table></div></details></td></tr><tr><td>1</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Silence { Start = 5211100, End = 5246770, Duration = 00:00:01.4862500 }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Start</td><td><div class=\"dni-plaintext\"><pre>5211100</pre></div></td></tr><tr><td>End</td><td><div class=\"dni-plaintext\"><pre>5246770</pre></div></td></tr><tr><td>Duration</td><td><span>00:00:01.4862500</span></td></tr></tbody></table></div></details></td></tr></tbody></table><style>\r\n",
       ".dni-code-hint {\r\n",
       "    font-style: italic;\r\n",
       "    overflow: hidden;\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview {\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview td {\r\n",
       "    vertical-align: top;\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "details.dni-treeview {\r\n",
       "    padding-left: 1em;\r\n",
       "}\r\n",
       "table td {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "table tr { \r\n",
       "    vertical-align: top; \r\n",
       "    margin: 0em 0px;\r\n",
       "}\r\n",
       "table tr td pre \r\n",
       "{ \r\n",
       "    vertical-align: top !important; \r\n",
       "    margin: 0em 0px !important;\r\n",
       "} \r\n",
       "table th {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>value</th></tr></thead><tbody><tr><td>0</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>AudioSegment { Start = 5246770, End = 22134528, Duration = 00:11:43 }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Start</td><td><div class=\"dni-plaintext\"><pre>5246770</pre></div></td></tr><tr><td>End</td><td><div class=\"dni-plaintext\"><pre>22134528</pre></div></td></tr><tr><td>Duration</td><td><span>00:11:43</span></td></tr></tbody></table></div></details></td></tr></tbody></table><style>\r\n",
       ".dni-code-hint {\r\n",
       "    font-style: italic;\r\n",
       "    overflow: hidden;\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview {\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview td {\r\n",
       "    vertical-align: top;\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "details.dni-treeview {\r\n",
       "    padding-left: 1em;\r\n",
       "}\r\n",
       "table td {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "table tr { \r\n",
       "    vertical-align: top; \r\n",
       "    margin: 0em 0px;\r\n",
       "}\r\n",
       "table tr td pre \r\n",
       "{ \r\n",
       "    vertical-align: top !important; \r\n",
       "    margin: 0em 0px !important;\r\n",
       "} \r\n",
       "table th {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var silences = FindSilences(earningsCallFilepath, -19);\n",
    "silences.Display();\n",
    "var audioSegments = FindAudibleSegments(earningsCallFilepath, silences);\n",
    "audioSegments.Display();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have audio segments we can create trimmed files to use with the `Whisper` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var trimmedFiles = new List<string>();\n",
    "\n",
    "foreach(var audioSegment in audioSegments ){\n",
    "    var trimmedFile = $\"./EarningsCall-{audioSegment.Start}-{audioSegment.End}.wav\";\n",
    "    trimmedFiles.Add(trimmedFile);\n",
    "    using (var reader = new AudioFileReader(earningsCallFilepath))\n",
    "    {\n",
    "        reader.Position = audioSegment.Start;\n",
    "        using (WaveFileWriter writer = new WaveFileWriter(trimmedFile, reader.WaveFormat))\n",
    "        {\n",
    "            var endPos = audioSegment.End;\n",
    "            byte[] buffer = new byte[1024];\n",
    "            while (reader.Position < endPos)\n",
    "            {\n",
    "                int bytesRequired = (int)(endPos - reader.Position);\n",
    "                if (bytesRequired > 0)\n",
    "                {\n",
    "                    int bytesToRead = Math.Min(bytesRequired, buffer.Length);\n",
    "                    int bytesRead = reader.Read(buffer, 0, bytesToRead);\n",
    "                    if (bytesRead > 0)\n",
    "                    {\n",
    "                        writer.Write(buffer, 0, bytesRead);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var transcript = new StringBuilder();\n",
    "\n",
    "foreach(var trimmedFile in trimmedFiles){\n",
    "    var audioFile = File.ReadAllBytes(trimmedFile);\n",
    "    var response = await client.GetAudioTranscriptionAsync(new AudioTranscriptionOptions(whisperDeployment, BinaryData.FromBytes(audioFile)));\n",
    "    transcript.AppendLine(response.Value.Text);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good afternoon, everyone, and welcome to FinTech Plus Sync's second quarter 2023 earnings call. I'm John Doe, CEO of FinTech Plus. We've had a stellar Q2 with a revenue of $125 million, a 25% increase year-over-year. Our gross profit margin stands at a solid 58%, due in part to cost efficiencies gained from our scalable business model. Our EBITDA has surged to $37.5 million, translating to a remarkable 30% EBITDA margin. Our net income for the quarter rose to $16 million, which is a noteworthy increase from $10 million in Q2 2022. Our total addressable market has grown substantially, thanks to the expansion of our high-yield savings product line and the new RoboAdvisor platform. We've been diversifying our asset-backed securities portfolio, investing heavily in collateralized debt obligations and residential mortgage-backed securities. We've also invested $25 million in AAA-rated corporate bonds, enhancing our risk-adjusted returns. As for our balance sheet, total assets reached $1.5 billion, with total liabilities at $900 million, leaving us with a solid equity base of $600 million. Our debt-to-equity ratio stands at 1.5, a healthy figure considering our expansionary phase. We continue to see substantial organic user growth, with customer acquisition costs dropping by 15% and lifetime value growing by 25%. Our LTVCAC ratio is at an impressive 3.5%. In terms of risk management, we have a value-at-risk model in place, with a 99% confidence level indicating that our maximum loss will not exceed $5 million in the next trading day. We've adopted a conservative approach to managing our leverage, and have a healthy Tier 1 capital ratio of 12.5%. Our forecast for the coming quarter is positive. We expect revenue to be around $135 million, an 8% quarter-over-quarter growth, driven primarily by our cutting-edge blockchain solutions and AI-driven predictive analytics. We're also excited about the upcoming IPO of our fintech subsidiary, Pay Plus, which we expect to raise $200 million, significantly bolstering our liquidity and paving the way for aggressive growth strategies. We thank our shareholders for their continued faith in us, and we look forward to an even more successful Q3. Thank you so much.\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using System.Text.RegularExpressions;\n",
    "var asciiText = Regex.Replace(transcript.ToString(), @\"[^\\u0000-\\u007F]+\", string.Empty);\n",
    "asciiText.Display();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will add formatting and punctuation to our transcript. Whisper generates a transcript with punctuation but without formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good afternoon, everyone, and welcome to FinTech Plus Sync's second quarter 2023 earnings call. I'm John Doe, CEO of FinTech Plus. We've had a stellar Q2 with a revenue of $125 million, a 25% increase year-over-year. Our gross profit margin stands at a solid 58%, due in part to cost efficiencies gained from our scalable business model. Our EBITDA has surged to $37.5 million, translating to a remarkable 30% EBITDA margin. Our net income for the quarter rose to $16 million, which is a noteworthy increase from $10 million in Q2 2022. Our total addressable market has grown substantially, thanks to the expansion of our high-yield savings product line and the new RoboAdvisor platform. We've been diversifying our asset-backed securities portfolio, investing heavily in collateralized debt obligations and residential mortgage-backed securities. We've also invested $25 million in AAA-rated corporate bonds, enhancing our risk-adjusted returns. As for our balance sheet, total assets reached $1.5 billion, with total liabilities at $900 million, leaving us with a solid equity base of $600 million. Our debt-to-equity ratio stands at 1.5, a healthy figure considering our expansionary phase. We continue to see substantial organic user growth, with customer acquisition costs dropping by 15% and lifetime value growing by 25%. Our LTVCAC ratio is at an impressive 3.5%. In terms of risk management, we have a value-at-risk model in place, with a 99% confidence level indicating that our maximum loss will not exceed $5 million in the next trading day. We've adopted a conservative approach to managing our leverage, and have a healthy Tier 1 capital ratio of 12.5%. Our forecast for the coming quarter is positive. We expect revenue to be around $135 million, an 8% quarter-over-quarter growth, driven primarily by our cutting-edge blockchain solutions and AI-driven predictive analytics. We're also excited about the upcoming IPO of our fintech subsidiary, Pay Plus, which we expect to raise $200 million, significantly bolstering our liquidity and paving the way for aggressive growth strategies. We thank our shareholders for their continued faith in us, and we look forward to an even more successful Q3. Thank you so much."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var punctuationResponse = await client.GetChatCompletionsAsync(new ChatCompletionsOptions{\n",
    "    Messages={\n",
    "        new ChatMessage(ChatRole.System, @\"You are a helpful assistant that adds punctuation to text. Preserve the original words and only insert necessary punctuation such as periods, commas, capialization, symbols like dollar sings or percentage signs, and formatting. Use only the context provided. If there is no context provided say, 'No context provided'\"),\n",
    "        new ChatMessage(ChatRole.User, asciiText)\n",
    "    },\n",
    "    Temperature = 0.0f,\n",
    "    DeploymentName = gptDeployment\n",
    "});\n",
    "\n",
    "var punctuatedTranscript  = punctuationResponse.Value.Choices[0].Message.Content;\n",
    "punctuatedTranscript.Display();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our audio file is a recording from a fake earnings call that includes a lot of financial products. This function can help ensure that if Whisper transcribes these financial product names incorrectly, that they can be corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good afternoon, everyone, and welcome to FinTech Plus Sync's second quarter 2023 earnings call. I'm John Doe, CEO of FinTech Plus. We've had a stellar Q2 with a revenue of $125 million, a 25% increase year-over-year. Our gross profit margin stands at a solid 58%, due in part to cost efficiencies gained from our scalable business model. Our EBITDA (Earnings Before Interest, Taxes, Depreciation, and Amortization) has surged to $37.5 million, translating to a remarkable 30% EBITDA margin. Our net income for the quarter rose to $16 million, which is a noteworthy increase from $10 million in Q2 2022. Our total addressable market has grown substantially, thanks to the expansion of our high-yield savings product line and the new RoboAdvisor platform. We've been diversifying our asset-backed securities portfolio, investing heavily in collateralized debt obligations and residential mortgage-backed securities. We've also invested $25 million in AAA-rated corporate bonds, enhancing our risk-adjusted returns. As for our balance sheet, total assets reached $1.5 billion, with total liabilities at $900 million, leaving us with a solid equity base of $600 million. Our debt-to-equity ratio stands at 1.5, a healthy figure considering our expansionary phase. We continue to see substantial organic user growth, with customer acquisition costs dropping by 15% and lifetime value growing by 25%. Our Lifetime Value to Customer Acquisition Cost (LTVCAC) ratio is at an impressive 3.5%. In terms of risk management, we have a Value at Risk (VaR) model in place, with a 99% confidence level indicating that our maximum loss will not exceed $5 million in the next trading day. We've adopted a conservative approach to managing our leverage, and have a healthy Tier 1 capital ratio of 12.5%. Our forecast for the coming quarter is positive. We expect revenue to be around $135 million, an 8% quarter-over-quarter growth, driven primarily by our cutting-edge blockchain solutions and AI-driven predictive analytics. We're also excited about the upcoming Initial Public Offering (IPO) of our fintech subsidiary, Pay Plus, which we expect to raise $200 million, significantly bolstering our liquidity and paving the way for aggressive growth strategies. We thank our shareholders for their continued faith in us, and we look forward to an even more successful Q3. Thank you so much."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var productAssistantResponse = await client.GetChatCompletionsAsync(new ChatCompletionsOptions{\n",
    "    Messages={\n",
    "        new ChatMessage(ChatRole.System, @\"You are an intelligent assistant specializing in financial products; your task is to process transcripts of earnings calls, ensuring that all references to financial products and common financial terms are in the correct format. For each financial product or common term that is typically abbreviated as an acronym, the full term should be spelled out followed by the acronym in parentheses. For example, '401k' should be transformed to '401(k) retirement savings plan', 'HSA' should be transformed to 'Health Savings Account (HSA)', 'ROA' should be transformed to 'Return on Assets (ROA)', 'VaR' should be transformed to 'Value at Risk (VaR)', and 'PB' should be transformed to 'Price to Book (PB) ratio'. Similarly, transform spoken numbers representing financial products into their numeric representations, followed by the full name of the product in parentheses. For instance, 'five two nine' to '529 (Education Savings Plan)' and 'four zero one k' to '401(k) (Retirement Savings Plan)'. However, be aware that some acronyms can have different meanings based on the context (e.g., 'LTV' can stand for 'Loan to Value' or 'Lifetime Value'). You will need to discern from the context which term is being referred to and apply the appropriate transformation. In cases where numerical figures or metrics are spelled out but do not represent specific financial products (like 'twenty three percent'), these should be left as is. Your role is to analyze and adjust financial product terminology in the text. Once you've done that, produce the adjusted transcript and a list of the words you've changed\"),\n",
    "        new ChatMessage(ChatRole.User, punctuatedTranscript)\n",
    "    },\n",
    "    Temperature = 0.0f,\n",
    "    DeploymentName = gptDeployment\n",
    "});\n",
    "\n",
    "var finalTranscript  = productAssistantResponse.Value.Choices[0].Message.Content;\n",
    "finalTranscript.Display();"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "csharp"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
