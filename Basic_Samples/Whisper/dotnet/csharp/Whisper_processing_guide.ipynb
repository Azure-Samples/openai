{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Whisper transcriptions: pre- & post-processing techniques\n",
    "\n",
    "This notebook offers a guide to improve the Whisper's transcriptions. We'll streamline your audio data via trimming and segmentation, enhancing Whisper's transcription quality. After transcriptions, we'll refine the output by adding punctuation, adjusting product terminology (e.g., 'five two nine' to '529'), and mitigating Unicode issues. These strategies will help improve the clarity of your transcriptions, but remember, customization based on your unique use-case may be beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "Install the Azure Open AI SDK using the below command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.AI.OpenAI, 1.0.0-beta.8</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Azure.AI.OpenAI, *-*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div><strong>Restore sources</strong><ul><li><span>https://pkgs.dev.azure.com/dnceng/public/_packaging/dotnet-tools/nuget/v3/index.json</span></li></ul></div><div></div><div></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#i \"nuget:https://pkgs.dev.azure.com/dnceng/public/_packaging/dotnet-tools/nuget/v3/index.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div><strong>Restore sources</strong><ul><li><span>https://pkgs.dev.azure.com/dnceng/public/_packaging/dotnet-tools/nuget/v3/index.json</span></li></ul></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.DotNet.Interactive.AIUtilities, 1.0.0-beta.23509.5</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget:Microsoft.DotNet.Interactive.AIUtilities, *-*\"\n",
    "\n",
    "using Microsoft.DotNet.Interactive;\n",
    "using Microsoft.DotNet.Interactive.AIUtilities;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var azureOpenAIKey = await Kernel.GetPasswordAsync(\"Provide your OPEN_AI_KEY\");\n",
    "\n",
    "// Your endpoint should look like the following https://YOUR_OPEN_AI_RESOURCE_NAME.openai.azure.com/\n",
    "var azureOpenAIEndpoint = await Kernel.GetInputAsync(\"Provide the OPEN_AI_ENDPOINT\");\n",
    "\n",
    "// Enter the deployment name you chose when you deployed the model.\n",
    "var deployment = await Kernel.GetInputAsync(\"Provide deployment name\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import namesapaces and create an instance of `OpenAiClient` using the `azureOpenAIEndpoint` and the `azureOpenAIKey`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Azure;\n",
    "using Azure.AI.OpenAI;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "OpenAIClient client = new (new Uri(azureOpenAIEndpoint), new AzureKeyCredential(azureOpenAIKey.GetClearTextPassword()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "To get started let's import a few different libraries:\n",
    "\n",
    " - [Naudio](https://github.com/naudio/NAudio) is a simple and easy-to-use library for audio processing tasks such as slicing, concatenating, and exporting audio files.\n",
    "\n",
    " - For our audio file, we'll use a fictional earnings call written by ChatGPT and read aloud by the author.This audio file is relatively short, but hopefully provides you with an illustrative idea of how these pre and post processing steps can be applied to any audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using System.Net.Http;\n",
    "using System.IO;\n",
    "\n",
    "// set download paths\n",
    "var earningsCallUrl = \"https://cdn.openai.com/API/examples/data/EarningsCall.wav\";\n",
    "\n",
    "//set local save locations\n",
    "var earningsCallFilepath = \"./EarningsCall.wav\";\n",
    "\n",
    "// download the file\n",
    "var httpClient = new HttpClient();\n",
    "using (var stream = await httpClient.GetStreamAsync(earningsCallUrl))\n",
    "{\n",
    "    using (var fileStream = new FileStream(earningsCallFilepath, FileMode.CreateNew))\n",
    "    {\n",
    "        await stream.CopyToAsync(fileStream);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>NAudio, 2.2.1</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: NAudio, 2.2.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using NAudio.Wave;\n",
    "using System.IO;\n",
    "\n",
    "public record Silence(long Start, long End, TimeSpan Duration);\n",
    "\n",
    "\n",
    "public bool IsSilence(float amplitude, sbyte threshold)\n",
    "    {\n",
    "        double dB = 20 * Math.Log10(Math.Abs(amplitude));\n",
    "        return dB < threshold;\n",
    "    }\n",
    "\n",
    "// Find silcence in the file so we can trim it and split by silences\n",
    "public Silence[] FindSilences(string fileName){\n",
    "    var silences = new List<Silence>();\n",
    "    using (var reader = new AudioFileReader(fileName))\n",
    "    {\n",
    "        var buffer = new float[reader.WaveFormat.SampleRate * 4];\n",
    "    \n",
    "        long start = 0;\n",
    "        bool eof = false;\n",
    "        sbyte silenceThreshold = -40;\n",
    "        long counter = 0;\n",
    "        bool detected = false;\n",
    "        while (!eof)\n",
    "        {\n",
    "            int samplesRead = reader.Read(buffer, 0, buffer.Length);\n",
    "            if (samplesRead == 0)\n",
    "                {\n",
    "                    eof = true;\n",
    "                    if (detected){\n",
    "                        double silenceSamples = (double)counter / reader.WaveFormat.Channels;\n",
    "                        double silenceDuration = (silenceSamples / reader.WaveFormat.SampleRate) * 1000;\n",
    "                        silences.Add(new Silence(start, counter, TimeSpan.FromMilliseconds(silenceDuration)));\n",
    "                    }\n",
    "                }\n",
    "\n",
    "            for (int n = 0; n < samplesRead; n++)\n",
    "            {\n",
    "                if (IsSilence(buffer[n], silenceThreshold))\n",
    "                {\n",
    "                    detected = true;\n",
    "                    counter++;\n",
    "                }\n",
    "                else{\n",
    "                    if(detected){\n",
    "                        double silenceSamples = (double)counter / reader.WaveFormat.Channels;\n",
    "                        double silenceDuration = (silenceSamples / reader.WaveFormat.SampleRate) * 1000;\n",
    "                        var last =silences.Count - 1;\n",
    "                        if (last >= 0){\n",
    "                            var gap = start - silences[last].End;\n",
    "                            var gapDuration = (double)gap / reader.WaveFormat.SampleRate * 1000;\n",
    "                            if (gapDuration < 500){\n",
    "                              silenceDuration = silenceDuration + silences[last].Duration.TotalMilliseconds;\n",
    "                             silences[last] = new Silence(silences[last].Start, counter + silences[last].End, TimeSpan.FromMilliseconds(silenceDuration));\n",
    "                          }\n",
    "                          else{\n",
    "                           silences.Add(new Silence(start, counter, TimeSpan.FromMilliseconds(silenceDuration)));\n",
    "                          }\n",
    "                      }\n",
    "                      else{\n",
    "                            silences.Add(new Silence(start, counter, TimeSpan.FromMilliseconds(silenceDuration)));\n",
    "                      }\n",
    "\n",
    "                        start = start + counter;\n",
    "                        counter = 0;\n",
    "                        detected = false;\n",
    "                    }\n",
    "                }            \n",
    "            }        \n",
    "        }\n",
    "    }\n",
    "    return silences.ToArray();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>value</th></tr></thead><tbody><tr><td>0</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Silence { Start = 0, End = 3268080, Duration = 00:02:16.1572809 }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Start</td><td><div class=\"dni-plaintext\"><pre>0</pre></div></td></tr><tr><td>End</td><td><div class=\"dni-plaintext\"><pre>3268080</pre></div></td></tr><tr><td>Duration</td><td><span>00:02:16.1572809</span></td></tr></tbody></table></div></details></td></tr><tr><td>1</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Silence { Start = 3268080, End = 27949, Duration = 00:00:01.1645416 }</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Start</td><td><div class=\"dni-plaintext\"><pre>3268080</pre></div></td></tr><tr><td>End</td><td><div class=\"dni-plaintext\"><pre>27949</pre></div></td></tr><tr><td>Duration</td><td><span>00:00:01.1645416</span></td></tr></tbody></table></div></details></td></tr></tbody></table><style>\r\n",
       ".dni-code-hint {\r\n",
       "    font-style: italic;\r\n",
       "    overflow: hidden;\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview {\r\n",
       "    white-space: nowrap;\r\n",
       "}\r\n",
       ".dni-treeview td {\r\n",
       "    vertical-align: top;\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "details.dni-treeview {\r\n",
       "    padding-left: 1em;\r\n",
       "}\r\n",
       "table td {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "table tr { \r\n",
       "    vertical-align: top; \r\n",
       "    margin: 0em 0px;\r\n",
       "}\r\n",
       "table tr td pre \r\n",
       "{ \r\n",
       "    vertical-align: top !important; \r\n",
       "    margin: 0em 0px !important;\r\n",
       "} \r\n",
       "table th {\r\n",
       "    text-align: start;\r\n",
       "}\r\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var silences = FindSilences(earningsCallFilepath);\n",
    "silences.Display();"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "csharp"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
